{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de amostras em X?(696, 300) e y:(696,)\n",
      "Acurácia do Modelo de Árvore de Decisão: 0.73\n",
      "Score do modelo de Árvore de Decisão: 0.7298850574712644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/t4cd3lc515j88jjkvk8hvrbw0000gn/T/ipykernel_75312/3350044027.py:32: DtypeWarning: Columns (35,36,37,41,42,43,44,45,46,47,48,49,50,51,52,56,57,58,59,60,61,65,66,67,68,69,70,71,72,73,74,75,76,80,81,82,83,84,85,89,90,91,92,93,94,95,96,97,98,99,100,104,105,106,107,108,109,113,114,115,116,117,118,119,120,121,122,123,124,128,129,130,131,132,133,137,138,139,140,141,142,143,144,145,146,147,148,152,153,154,155,156,157,161,162,163,164,165,166,167,168,169,170,171,172,176,177,178,179,180,181,185,186,187,188,189,190,191,192,193,194,195,196,200,201,202,203,204,205,209,210,211,212,213,214,215,216,217,218,219,220,224,225,226,227,228,229,233,234,235,236,237,238,239,240,241,242,243,244,248,249,250,251,252,253,257,258,259,260,261,262,263,264,265,266,267,268,272,273,274) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  matches_train_data = pd.read_csv('../../data/raw/matches.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "## Definindo as colunas que serão usadas para treinar o modelo\n",
    "team_map_results_columns_to_add  = [\"Id\", \"Kills\", \"Deaths\", \"PlusMinus\", \"Adr\", \"Kast\", \"Rating\"]\n",
    "team_map_results_columns_to_drop = [\"Id\", \"Kills\", \"Deaths\", \"Adr\", \"Kast\"]\n",
    "\n",
    "map_results = [f\"map{map_num}Team{team_num}Side{side}Player{player_num}{attribute}\"\n",
    "                for map_num in range(1, 6) \n",
    "                for team_num in range(1, 3) \n",
    "                for player_num in range(1, 6)\n",
    "                for attribute in team_map_results_columns_to_add\n",
    "                for side in [\"Both\", \"CounterTerrorist\", \"Terrorist\"]]\n",
    "\n",
    "## Definindo as colunas que serão retiradas para a análise\n",
    "drop_columns = [f\"map{map_num}Team{team_num}Side{side}Player{player_num}{attribute}\"\n",
    "                for map_num in range(1, 6) \n",
    "                for team_num in range(1, 3) \n",
    "                for player_num in range(1, 6)\n",
    "                for attribute in team_map_results_columns_to_drop\n",
    "                for side in [\"Both\", \"CounterTerrorist\", \"Terrorist\"]]\n",
    "\n",
    "### Listando as colunas que serão usadas das partidas, como: Jogadores, Mortes, Assistências etc.\n",
    "matches_train_data_columns = ['eventId', 'matchId', 'mapBestOf'] + map_results\n",
    "\n",
    "matches_results_train_data = pd.read_csv('../../data/raw/matches_results.csv')\n",
    "matches_train_data = pd.read_csv('../../data/raw/matches.csv')\n",
    "\n",
    "matches_train_data = matches_train_data[matches_train_data_columns]\n",
    "\n",
    "matches_results_train_data_columns = ['eventId', 'matchId', 'TeamOneScore', 'TeamTwoScore', 'teamOneWon', 'teamTwoWon']\n",
    "matches_results_train_data = matches_results_train_data[[col for col in matches_results_train_data.columns if any(s in col for s in matches_results_train_data_columns)]]\n",
    "\n",
    "## Combinando os dados gerais das partidas com os detalhes das partidas\n",
    "full_matches_train_data = pd.merge(matches_results_train_data, matches_train_data, on='matchId', how='inner')\n",
    "\n",
    "## Data Wrangling\n",
    "full_matches_train_data.fillna(0, inplace=True)\n",
    "full_matches_train_data.replace(\"Not Available\", 0, inplace=True)\n",
    "full_matches_train_data.drop(['eventId_y', 'eventId_x', 'matchId'], axis=1, inplace=True)\n",
    "\n",
    "full_matches_train_data.drop(drop_columns, axis=1, inplace=True)\n",
    "full_matches_train_data.drop(['mapBestOf'], axis=1, inplace=True)\n",
    "\n",
    "# Features (colunas que serão utilizadas para fazer a previsão)\n",
    "X = full_matches_train_data.drop(['teamOneWon', 'teamTwoWon'], axis=1)\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Target (coluna que será prevista)\n",
    "y = full_matches_train_data['teamOneWon']\n",
    "y = y.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "print(f\"Número de amostras em X?{X.shape} e y:{y.shape}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "# Treinar o modelo com a base de treino\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões com o conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular a acurácia\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Acurácia do Modelo de Árvore de Decisão: {accuracy:.2f}')\n",
    "print(f\"Score do modelo de Árvore de Decisão: {model.score(X_test, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mba-scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
